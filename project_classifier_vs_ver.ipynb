{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_classifier_vs_ver.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0Zb1fmOetvr9",
        "nFSFaXqxyhaH",
        "N-3LFa1m0LD5",
        "7QiOuNxsEpZU",
        "zG9nObyHFlBF"
      ],
      "mount_file_id": "1553uHnrWq5ZRfoLwO5W5Q-TAbDCcHJCs",
      "authorship_tag": "ABX9TyP5NQ6kZy0nU7WHExc1hr65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab0a33f3d4fb415b81a47328e6ea0f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f291824c02f4b72ae7ccb407ab2305d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_111a5af751f14baead3bcd4102b1f507",
              "IPY_MODEL_4fa2ce766a714926bb335efb29ea6cea"
            ]
          }
        },
        "0f291824c02f4b72ae7ccb407ab2305d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "111a5af751f14baead3bcd4102b1f507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efa6220746804d32b8cf78fc2477b156",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4015c70bf362467a8044a9efdbe43606"
          }
        },
        "4fa2ce766a714926bb335efb29ea6cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6d2d1bc10df4c8294a0d2adfa3b097c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:11&lt;00:00, 51.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b30ae6bc85e74136a8ef3d670ec9299f"
          }
        },
        "efa6220746804d32b8cf78fc2477b156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4015c70bf362467a8044a9efdbe43606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6d2d1bc10df4c8294a0d2adfa3b097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b30ae6bc85e74136a8ef3d670ec9299f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b13c8d8a352f47ffa10e3a6f32632998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67bf1f55c408443e8b069b84e38939be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_670436948444482baacc8f7c9aa6f70a",
              "IPY_MODEL_1977ef3595fc42eab3cb3fbafca90403"
            ]
          }
        },
        "67bf1f55c408443e8b069b84e38939be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "670436948444482baacc8f7c9aa6f70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20e1072ca25543b3b907a928746ddb51",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4dbc5af2c3d48cc928d7b6b280bee8e"
          }
        },
        "1977ef3595fc42eab3cb3fbafca90403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7600d852a3344149b7f3544f9f955b08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e3c79492f704dee9a101a435f796324"
          }
        },
        "20e1072ca25543b3b907a928746ddb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4dbc5af2c3d48cc928d7b6b280bee8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7600d852a3344149b7f3544f9f955b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e3c79492f704dee9a101a435f796324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f62c59e748104154a3783193b8501945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7068c423a19047c79734cf6d705b0538",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef6a71cbd3204a719ca540346e679168",
              "IPY_MODEL_7dc4ab9ed4df4b589306d6926860938e"
            ]
          }
        },
        "7068c423a19047c79734cf6d705b0538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef6a71cbd3204a719ca540346e679168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a624041561d6433fa8f67210535c8028",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30bd662228094bc38e4550f0f1eb3233"
          }
        },
        "7dc4ab9ed4df4b589306d6926860938e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0191c522fbad4944a6dac2e130bf3501",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:10&lt;00:00, 43.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84aa379fbf6d458a80c42561c5477624"
          }
        },
        "a624041561d6433fa8f67210535c8028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30bd662228094bc38e4550f0f1eb3233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0191c522fbad4944a6dac2e130bf3501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84aa379fbf6d458a80c42561c5477624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edaed01585a64776b765e17e45622a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08b2aec1ce5d4f8799f2b4217ac51f6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbfe81d8d4ce425cb8f41eac9c39c09e",
              "IPY_MODEL_d7a1d07b033f4d2f920e82c0cafe53e3"
            ]
          }
        },
        "08b2aec1ce5d4f8799f2b4217ac51f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbfe81d8d4ce425cb8f41eac9c39c09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7e9cc5d778746d490aa611a9fca6a3f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f367a156ee8442daba2fc56cae690ab"
          }
        },
        "d7a1d07b033f4d2f920e82c0cafe53e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80363adf2e3244dcac247a9b47d64a33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 77.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0583efb6b264093b756fb27204f531d"
          }
        },
        "b7e9cc5d778746d490aa611a9fca6a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f367a156ee8442daba2fc56cae690ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80363adf2e3244dcac247a9b47d64a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0583efb6b264093b756fb27204f531d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87b51049f7194b6b9992f50647def398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_499fc2417584413993b25d16f1bef598",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d56039ac5d124241b8fbada6fbdd88fa",
              "IPY_MODEL_9b9bd30cb9884d8d949704415315da5e"
            ]
          }
        },
        "499fc2417584413993b25d16f1bef598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d56039ac5d124241b8fbada6fbdd88fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6dc51faf72f5424f9899179fc7eff57f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_831bdad1891b43bf805022dfc703e349"
          }
        },
        "9b9bd30cb9884d8d949704415315da5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bfe33bdca0e46508a3ea4143f50e5b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 42.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03fd13a1e66a4056afcd3603cef19a51"
          }
        },
        "6dc51faf72f5424f9899179fc7eff57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "831bdad1891b43bf805022dfc703e349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bfe33bdca0e46508a3ea4143f50e5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03fd13a1e66a4056afcd3603cef19a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabanto22/NLP-Project/blob/main/project_classifier_vs_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh3QqvrUMccZ",
        "outputId": "dda54ff2-f972-40fb-beed-a19084d3cc8f"
      },
      "source": [
        "!pip install torch \n",
        "!pip install torchtext \n",
        "!pip install torchvision \n",
        "!pip install transformers\n",
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYHbZ-1Er7Ec"
      },
      "source": [
        "# Rumour Classification\n",
        "A BERT based binary classification task applied on main tweets and replies to predict whether the main tweet is a rumour or not. The pre-trained BERT model is implemented and fine-tuned using PyTorch and Huggingface transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YKb5s5LupdL"
      },
      "source": [
        "## Using PyTorch and Huggingface libraries\n",
        "The following are the libraries needed to preprocess the Twitter files and fine-tune the pre-trained BERT model for our Classification task. It is important to notice that we set all seeds to have reproducible results when we re-run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grlD1fabFKdx"
      },
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import preprocessor as p\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Models\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Training\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global definitions\n",
        "PROJECT_DATA = '/content/drive/MyDrive/Colab Notebooks/NLP_Project/project-data/'\n",
        "MODELS = '/content/drive/MyDrive/Colab Notebooks/NLP_Project/models'\n",
        "\n",
        "# BERT model\n",
        "BERT_MODEL = \"bert-base-uncased\"\n",
        "\n",
        "# Model Parameters\n",
        "FREEZE = False  # update encoder weights and classification layer weights\n",
        "MAXLEN = 64  # maximum length of the tokenized input sentence pair\n",
        "BS = 16  # batch size\n",
        "ITERS_TO_ACCUMULATE = 2  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n",
        "LR = 3e-5  # learning rate\n",
        "EPOCHS = 4  # number of training epochs\n",
        "\n",
        "# Set seed for reproducibility of results\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# Use gpu if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M62vHtytM_3"
      },
      "source": [
        "## Reading and Merging data with class labels\n",
        "We define below the methods for reading and merging twitter data from JSONL files with class labels from JSON files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIaPJhYATrvZ"
      },
      "source": [
        "def read_data(filename):\n",
        "    \"\"\"\n",
        "    Read twitter datasets.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame()\n",
        "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            line = json.loads(line)\n",
        "            tweet_id = line[0][\"id_str\"]\n",
        "            tweet = p.clean(line[0][\"text\"])\n",
        "            comments = \"\"\n",
        "            for row in line:\n",
        "                # use tweet preprocessor to clean text\n",
        "                comments += \" \" + p.clean(row[\"text\"]) + \".\"\n",
        "            data = data.append({\"id\":tweet_id,\"text\":tweet,\"comments\":comments}, ignore_index=True)\n",
        "    f.close()\n",
        "\n",
        "    return data\n",
        "\n",
        "    \n",
        "def read_label(filename):\n",
        "    \"\"\"\n",
        "    Read class labels.\n",
        "    \"\"\"\n",
        "    label = pd.DataFrame()\n",
        "\n",
        "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
        "        label = pd.DataFrame.from_dict(json.load(f), orient=\"index\").reset_index()\n",
        "        label.columns = [\"id\", \"label\"]\n",
        "    f.close()\n",
        "\n",
        "    return label\n",
        "\n",
        "    \n",
        "def merge_data_label(data, label):\n",
        "    \"\"\"\n",
        "    Merge train data with class labels and class label codes for prediction.\n",
        "    \"\"\"\n",
        "    data = pd.merge(data, label, on=\"id\", how=\"outer\")\n",
        "    data.label = pd.Categorical(data.label)\n",
        "    class_labels = dict(enumerate(data.label.cat.categories))\n",
        "    data['label'] = data.label.cat.codes\n",
        "\n",
        "    # write predicted labels to json file\n",
        "    with open(PROJECT_DATA + 'labels.json', 'w') as f:\n",
        "        json.dump(class_labels, f, separators=(',', ':'))\n",
        "    f.close()\n",
        "\n",
        "    return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zb1fmOetvr9"
      },
      "source": [
        "## Generating CSV data files\n",
        "The following methods will be used to save the loaded and merged train, validation, and test Twitter files to CSV files for later use. The CSV files are generated so as not to repeatedly load the large JSONL files to memory when re-running the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdQrXDxwHS8p"
      },
      "source": [
        "def save_data_to_csv():\n",
        "    \"\"\"\n",
        "    Read and extract datasets from files.\n",
        "    \"\"\"\n",
        "    # read data (jsonl files)\n",
        "    train_data = read_data(PROJECT_DATA + 'train.data.jsonl')\n",
        "    dev_data = read_data(PROJECT_DATA + 'dev.data.jsonl')\n",
        "    test_data = read_data(PROJECT_DATA + 'test.data.jsonl')\n",
        "    covid_data = read_data(PROJECT_DATA + 'covid.data.jsonl')\n",
        "\n",
        "    # read labels (json files)\n",
        "    train_label = read_label(PROJECT_DATA + 'train.label.json')\n",
        "    dev_label = read_label(PROJECT_DATA + 'dev.label.json')\n",
        "\n",
        "    # merge data with class labels\n",
        "    train_data = merge_data_label(train_data, train_label)\n",
        "    dev_data = merge_data_label(dev_data, dev_label)\n",
        "\n",
        "    # write filetered data to csv\n",
        "    open(PROJECT_DATA + 'train.csv','w', newline='').write(train_data.to_csv(index=False))\n",
        "    open(PROJECT_DATA + 'dev.csv','w', newline='').write(dev_data.to_csv(index=False))\n",
        "    open(PROJECT_DATA + 'test.csv','w', newline='').write(test_data.to_csv(index=False))\n",
        "    open(PROJECT_DATA + 'covid.csv','w', newline='').write(covid_data.to_csv(index=False))\n",
        "\n",
        "\n",
        "def check_input_files(filename):\n",
        "    \"\"\"\n",
        "    Check input files if they exist.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        f = open(filename,'r')\n",
        "        f.close()\n",
        "    except:\n",
        "        # read and process all input datasets\n",
        "        save_data_to_csv()\n",
        "\n",
        "\n",
        "def read_csv_datasets(filename):\n",
        "    # check if input files exist\n",
        "    check_input_files(filename)\n",
        "\n",
        "    # read datasets\n",
        "    df = pd.read_csv(filename, dtype={'id':str})\n",
        "\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFSFaXqxyhaH"
      },
      "source": [
        "## Preparing and Tokenizing our Dataset\n",
        "We define below a custom Dataset class to tokenize a pair of tweets (main tweet, main tweet+replies) using pre-trained BERT tokenizer to get token ids, attention masks, and token type ids converted to tensors which will be used as inputs to BERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwFLEKsgH3rL"
      },
      "source": [
        "class TweetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, maxlen, with_labels=True, bert_model='bert-base-uncased'):\n",
        "\n",
        "        self.data = data\n",
        "        self.with_labels = with_labels \n",
        "        \n",
        "        # Initialize BERT tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n",
        "        self.maxlen = maxlen\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
        "        sent1 = str(self.data.loc[index, 'text'])\n",
        "        sent2 = str(self.data.loc[index, 'comments'])\n",
        "\n",
        "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
        "        encoded_pair = self.tokenizer(sent1, sent2, \n",
        "                                      padding='max_length',  # Pad to max_length\n",
        "                                      truncation=True,  # Truncate to max_length\n",
        "                                      max_length=self.maxlen,  \n",
        "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
        "        \n",
        "        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
        "        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
        "        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
        "\n",
        "        if self.with_labels:  # True if the dataset has labels (train and validation dataset)\n",
        "            label = self.data.loc[index, 'label']\n",
        "            return token_ids, attn_masks, token_type_ids, label  \n",
        "        else:  # for test set that has no labels\n",
        "            return token_ids, attn_masks, token_type_ids"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-3LFa1m0LD5"
      },
      "source": [
        "## BERT model\n",
        "This is the BERT model, a simple feed forward network with one dropout layer before feeding the results to the classifier layer. We will not be feezing the BERT layers for this task as we want to train all layers for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj7YDMEOH_bP"
      },
      "source": [
        "class SentencePairClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_model=\"bert-base-uncased\", freeze_bert=False):\n",
        "        super(SentencePairClassifier, self).__init__()\n",
        "        #  Instantiating BERT-based model object\n",
        "        self.bert_layer = AutoModel.from_pretrained(bert_model)\n",
        "        \n",
        "        # Freeze bert layers and only train the classification layer weights\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        # Classification layer\n",
        "        # input dimension is 768 because [CLS] embedding has a dimension of 768\n",
        "        # output dimension is 1 because we're working with a binary classification problem\n",
        "        self.cls_layer = nn.Linear(768, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    @autocast()  # run in mixed precision\n",
        "    def forward(self, input_ids, attn_masks, token_type_ids):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -input_ids : Tensor  containing token ids\n",
        "            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n",
        "            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n",
        "        '''\n",
        "\n",
        "        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n",
        "        output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n",
        "        \n",
        "        # the last layer hidden-state of the first token of the sequence (classification token) \n",
        "        # further processed by a Linear layer and a Tanh activation function.\n",
        "        logits = self.dropout(output['pooler_output'])\n",
        "        \n",
        "        # Feeding to the classifier layer \n",
        "        logits = self.cls_layer(logits)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMQ11dOzBaFr"
      },
      "source": [
        "### Plotting accuracy and loss to file\n",
        "The following method will be used to plot the training and validation accuracy and loss of the model on each epoch while fine-tuning the BERT model for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lz69dVHJnRe"
      },
      "source": [
        "def plot_train_perf(train_losses, val_losses, train_accuracies, val_accuracies, best_model):\n",
        "    \"\"\"\n",
        "    Create a plot analysis of model loss and accuracy across training epochs.\n",
        "    \"\"\"\n",
        "    acc = train_accuracies\n",
        "    val_acc = val_accuracies\n",
        "    loss = train_losses\n",
        "    val_loss = val_losses\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    path_to_fig = MODELS + '/accuracy-' + best_model + '.png'\n",
        "    fig.savefig(path_to_fig,dpi=300)\n",
        "    fig.show()\n",
        "    plt.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBN7RnUnB5TJ"
      },
      "source": [
        "### Fine-tuning the BERT model\n",
        "The following methods will be used for fine-tuning the pre-trained BERT model with **AdamW** optimizer and using **BCEWithLogitsLoss** loss function. The class weights are computed and feed as input to the loss function to handle any imbalance in the training data. Fine-tuning takes 4 epochs, but we will notice that this is more than enough to train the BERT model for our task as loss starts to increase from the 3rd epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCAehq3sIIqo"
      },
      "source": [
        "def compute_class_weights(train_df):\n",
        "    #compute the class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', \n",
        "                                        classes=np.unique(train_df.label.values), \n",
        "                                        y=train_df.label.values)\n",
        "\n",
        "    # converting list of class weights to a tensor\n",
        "    weights = torch.tensor(class_weights[1]/class_weights[0], dtype=torch.float)\n",
        "\n",
        "    # push to GPU\n",
        "    weights = weights.to(device)\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def evaluate(net, device, criterion, dataloader):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (seq, attn_masks, token_type_ids, labels) in dataloader:\n",
        "            seq, attn_masks, token_type_ids, labels = \\\n",
        "                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n",
        "            logits = net(seq, attn_masks, token_type_ids)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            mean_acc += get_accuracy_from_logits(logits, labels).item()\n",
        "            count += 1\n",
        "\n",
        "    return mean_loss / count, mean_acc / count\n",
        "\n",
        "\n",
        "def train(net, bert_model, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n",
        "\n",
        "    best_loss = np.Inf\n",
        "    best_acc = 0\n",
        "    best_ep = 1\n",
        "    nb_iterations = len(train_loader)\n",
        "    print_every = nb_iterations // 5  # print the training loss 5 times per epoch\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        iter = 0\n",
        "        for (seq, attn_masks, token_type_ids, labels) in train_loader:\n",
        "            iter += 1\n",
        "            #Converting these to tensors\n",
        "            seq, attn_masks, token_type_ids, labels = \\\n",
        "                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n",
        "    \n",
        "            # Enables autocasting for the forward pass (model + loss)\n",
        "            with autocast():\n",
        "                # Obtaining the logits from the model\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "\n",
        "                # Computing loss\n",
        "                loss = criterion(logits.squeeze(-1), labels.float())\n",
        "                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n",
        "\n",
        "                # Computing accuracy\n",
        "                acc = get_accuracy_from_logits(logits, labels)\n",
        "                total_acc += acc\n",
        "\n",
        "            # Backpropagating the gradients\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if iter % iters_to_accumulate == 0:\n",
        "                # Optimization step\n",
        "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
        "                # otherwise, opti.step() is skipped.\n",
        "                scaler.step(opti)\n",
        "                # Updates the scale for next iteration.\n",
        "                scaler.update()\n",
        "                # Adjust the learning rate based on the number of iterations.\n",
        "                lr_scheduler.step()\n",
        "                # Clear gradients\n",
        "                opti.zero_grad()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if iter % print_every == 0 and iter != 0:  # Print training loss information\n",
        "                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n",
        "                      .format(iter, nb_iterations, ep+1, running_loss / print_every))\n",
        "                \n",
        "                total_loss += running_loss\n",
        "                \n",
        "                running_loss = 0.0\n",
        "\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        train_accuracies.append(total_acc / len(train_loader))\n",
        "        \n",
        "        val_loss, val_acc = evaluate(net, device, criterion, val_loader)  # Compute validation loss and accuracy\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        print(\"\\nEpoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            print(\"Best validation loss improved from {} to {}\\n\".format(best_loss, val_loss))\n",
        "            net_copy = copy.deepcopy(net)  # save a copy of the model\n",
        "            best_loss = val_loss\n",
        "            best_acc = val_acc\n",
        "            best_ep = ep + 1\n",
        "\n",
        "    # Saving the model\n",
        "    path_to_model = MODELS + '/{}_lr_{}_val_loss_{}_acc_{}_ep_{}.pt'.format(bert_model, lr, round(best_loss, 5), round(best_acc, 5), best_ep)\n",
        "    best_model = '{}_lr_{}_val_loss_{}_acc_{}_ep_{}'.format(bert_model, lr, round(best_loss, 5), round(best_acc, 5), best_ep)\n",
        "    torch.save(net_copy.state_dict(), path_to_model)\n",
        "    print(\"Finished training!\")\n",
        "    print(\"The model has been saved in {}\".format(path_to_model))\n",
        "\n",
        "    del loss\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Plot performance of model on each epoch\n",
        "    plot_train_perf(train_losses, val_losses, train_accuracies, val_accuracies, best_model)\n",
        "\n",
        "    return path_to_model\n",
        "\n",
        "\n",
        "def finetuneBERT(train_df, dev_df):\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(MODELS)\n",
        "        print(\"Directory:\", MODELS, \"created.\")\n",
        "    except:\n",
        "        print(\"Directory:\", MODELS, \"already exists.\")\n",
        "\n",
        "    # Read train and validation datasets\n",
        "    print(\"Reading training data...\")\n",
        "    train_set = TweetDataset(train_df, MAXLEN, BERT_MODEL)\n",
        "    print(\"Reading validation data...\")\n",
        "    val_set = TweetDataset(dev_df, MAXLEN, BERT_MODEL)\n",
        "    \n",
        "    # Create instances of training and validation dataloaders\n",
        "    train_loader = DataLoader(train_set, batch_size=BS, num_workers=2)\n",
        "    val_loader = DataLoader(val_set, batch_size=BS, num_workers=2)\n",
        "    print(\"Done preprocessing training and development data.\")\n",
        "\n",
        "    net = SentencePairClassifier(BERT_MODEL, freeze_bert=FREEZE)\n",
        "    net.to(device)\n",
        "\n",
        "    # model parameters for fine-tuning\n",
        "    weights = compute_class_weights(train_df)\n",
        "    criterion = nn.BCEWithLogitsLoss(weight=weights)\n",
        "    opti = AdamW(net.parameters(), lr=LR, weight_decay=1e-2)\n",
        "    num_warmup_steps = 0 # The number of steps for the warmup phase.\n",
        "    num_training_steps = (len(train_loader) // ITERS_TO_ACCUMULATE) * EPOCHS  # Necessary to take into account Gradient accumulation\n",
        "    lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "    # start training for downstream task\n",
        "    path_to_model = train(net, BERT_MODEL, criterion, opti, LR, lr_scheduler, train_loader, val_loader, EPOCHS, ITERS_TO_ACCUMULATE)\n",
        "\n",
        "    return path_to_model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKHj2bzQDRgw"
      },
      "source": [
        "### Making predictions using fine-tuned BERT model\n",
        "The following methods will be used to make predictions using the BERT model we trained in the previous steps. We will also be saving the predictions to a file for potential future use or analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4DuZzMvKC-U"
      },
      "source": [
        "def get_probs_from_logits(logits):\n",
        "    \"\"\"\n",
        "    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n",
        "    \"\"\"\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "\n",
        "    return probs.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def predict_to_file(net, device, dataloader, with_labels=True, result_file=PROJECT_DATA + \"output.txt\"):\n",
        "    \"\"\"\n",
        "    Predict the probabilities on a dataset with or without labels and print the result in a file\n",
        "    \"\"\"\n",
        "    net.eval()\n",
        "    w = open(result_file, 'w')\n",
        "    probs_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if with_labels:\n",
        "            for seq, attn_masks, token_type_ids, _ in dataloader:\n",
        "                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
        "                probs_all += probs.tolist()\n",
        "        else:\n",
        "            for seq, attn_masks, token_type_ids in dataloader:\n",
        "                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n",
        "                logits = net(seq, attn_masks, token_type_ids)\n",
        "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
        "                probs_all += probs.tolist()\n",
        "\n",
        "    w.writelines(str(prob)+'\\n' for prob in probs_all)\n",
        "    w.close()\n",
        "\n",
        "\n",
        "def extract_class_labels():\n",
        "    # read class labels from json file\n",
        "    label = pd.DataFrame()\n",
        "    with open(PROJECT_DATA + 'labels.json', 'r', encoding=\"utf8\") as f:\n",
        "        label = json.load(f)\n",
        "    f.close()\n",
        "    return label\n",
        "\n",
        "\n",
        "def save_result(data, path_to_output_file=PROJECT_DATA + \"output.txt\", save_file=PROJECT_DATA + \"output.json\"):\n",
        "    \"\"\"\n",
        "    Save predictions on the test data to json file.\n",
        "    \"\"\"\n",
        "    probs_test = pd.read_csv(path_to_output_file, header=None)[0]  # read prediction probabilities from file\n",
        "    preds_test=(probs_test>=0.5).astype('uint8') # predicted labels using the fixed threshold of 0.5\n",
        "\n",
        "    labels = extract_class_labels()\n",
        "    pred_label = {}\n",
        "    for i in range(len(preds_test)):\n",
        "        code = str(preds_test[i])\n",
        "        text_id = str(data.iloc[i]['id'])\n",
        "        pred_label[text_id] = labels[code]\n",
        "        \n",
        "    # write predicted labels to json file\n",
        "    with open(save_file, 'w') as f:\n",
        "        json.dump(pred_label, f, separators=(',', ':'))\n",
        "    f.close()\n",
        "\n",
        "    print(\"Predictions are available in : {}\".format(save_file))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QiOuNxsEpZU"
      },
      "source": [
        "## Training the model\n",
        "Finally, we fine-tune and train BERT model for our classification task using training and validation sets from Twitter data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899,
          "referenced_widgets": [
            "ab0a33f3d4fb415b81a47328e6ea0f0d",
            "0f291824c02f4b72ae7ccb407ab2305d",
            "111a5af751f14baead3bcd4102b1f507",
            "4fa2ce766a714926bb335efb29ea6cea",
            "efa6220746804d32b8cf78fc2477b156",
            "4015c70bf362467a8044a9efdbe43606",
            "c6d2d1bc10df4c8294a0d2adfa3b097c",
            "b30ae6bc85e74136a8ef3d670ec9299f",
            "b13c8d8a352f47ffa10e3a6f32632998",
            "67bf1f55c408443e8b069b84e38939be",
            "670436948444482baacc8f7c9aa6f70a",
            "1977ef3595fc42eab3cb3fbafca90403",
            "20e1072ca25543b3b907a928746ddb51",
            "c4dbc5af2c3d48cc928d7b6b280bee8e",
            "7600d852a3344149b7f3544f9f955b08",
            "7e3c79492f704dee9a101a435f796324",
            "f62c59e748104154a3783193b8501945",
            "7068c423a19047c79734cf6d705b0538",
            "ef6a71cbd3204a719ca540346e679168",
            "7dc4ab9ed4df4b589306d6926860938e",
            "a624041561d6433fa8f67210535c8028",
            "30bd662228094bc38e4550f0f1eb3233",
            "0191c522fbad4944a6dac2e130bf3501",
            "84aa379fbf6d458a80c42561c5477624",
            "edaed01585a64776b765e17e45622a04",
            "08b2aec1ce5d4f8799f2b4217ac51f6d",
            "cbfe81d8d4ce425cb8f41eac9c39c09e",
            "d7a1d07b033f4d2f920e82c0cafe53e3",
            "b7e9cc5d778746d490aa611a9fca6a3f",
            "9f367a156ee8442daba2fc56cae690ab",
            "80363adf2e3244dcac247a9b47d64a33",
            "c0583efb6b264093b756fb27204f531d",
            "87b51049f7194b6b9992f50647def398",
            "499fc2417584413993b25d16f1bef598",
            "d56039ac5d124241b8fbada6fbdd88fa",
            "9b9bd30cb9884d8d949704415315da5e",
            "6dc51faf72f5424f9899179fc7eff57f",
            "831bdad1891b43bf805022dfc703e349",
            "7bfe33bdca0e46508a3ea4143f50e5b8",
            "03fd13a1e66a4056afcd3603cef19a51"
          ]
        },
        "id": "LoDv3VDbPDw1",
        "outputId": "d2f11b28-2ff2-4e95-b2db-ac6591a43f4d"
      },
      "source": [
        "# read train and dev datasets\n",
        "train_df = read_csv_datasets(PROJECT_DATA + 'train.csv')\n",
        "dev_df = read_csv_datasets(PROJECT_DATA + 'dev.csv')\n",
        "\n",
        "path_to_model = finetuneBERT(train_df, dev_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory: /content/drive/MyDrive/Colab Notebooks/NLP_Project/models already exists.\n",
            "Reading training data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab0a33f3d4fb415b81a47328e6ea0f0d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13c8d8a352f47ffa10e3a6f32632998",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f62c59e748104154a3783193b8501945",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edaed01585a64776b765e17e45622a04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading validation data...\n",
            "Done preprocessing training and development data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b51049f7194b6b9992f50647def398",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 58/291 of epoch 1 complete. Loss : 0.5676862176122337 \n",
            "Iteration 116/291 of epoch 1 complete. Loss : 0.4282150173495556 \n",
            "Iteration 174/291 of epoch 1 complete. Loss : 0.38165400588306886 \n",
            "Iteration 232/291 of epoch 1 complete. Loss : 0.3509611385906565 \n",
            "Iteration 290/291 of epoch 1 complete. Loss : 0.3654688457990515 \n",
            "\n",
            "Epoch 1 complete! Validation Loss : 0.6043922401763298\n",
            "Best validation loss improved from inf to 0.6043922401763298\n",
            "\n",
            "Iteration 58/291 of epoch 2 complete. Loss : 0.3304579137214299 \n",
            "Iteration 116/291 of epoch 2 complete. Loss : 0.24677554607905192 \n",
            "Iteration 174/291 of epoch 2 complete. Loss : 0.23875260301705065 \n",
            "Iteration 232/291 of epoch 2 complete. Loss : 0.24365975887610994 \n",
            "Iteration 290/291 of epoch 2 complete. Loss : 0.218277288857719 \n",
            "\n",
            "Epoch 2 complete! Validation Loss : 0.5398962449383091\n",
            "Best validation loss improved from 0.6043922401763298 to 0.5398962449383091\n",
            "\n",
            "Iteration 58/291 of epoch 3 complete. Loss : 0.20075176559902472 \n",
            "Iteration 116/291 of epoch 3 complete. Loss : 0.14982255818001156 \n",
            "Iteration 174/291 of epoch 3 complete. Loss : 0.1217803783586313 \n",
            "Iteration 232/291 of epoch 3 complete. Loss : 0.1652117142582248 \n",
            "Iteration 290/291 of epoch 3 complete. Loss : 0.12390266956183417 \n",
            "\n",
            "Epoch 3 complete! Validation Loss : 0.5901680898827475\n",
            "Iteration 58/291 of epoch 4 complete. Loss : 0.10931640641828036 \n",
            "Iteration 116/291 of epoch 4 complete. Loss : 0.09023590201255062 \n",
            "Iteration 174/291 of epoch 4 complete. Loss : 0.06938638427326906 \n",
            "Iteration 232/291 of epoch 4 complete. Loss : 0.07927195714176472 \n",
            "Iteration 290/291 of epoch 4 complete. Loss : 0.06879784530510419 \n",
            "\n",
            "Epoch 4 complete! Validation Loss : 0.6269492193855144\n",
            "Finished training!\n",
            "The model has been saved in /content/drive/MyDrive/Colab Notebooks/NLP_Project/models/bert-base-uncased_lr_3e-05_val_loss_0.5399_acc_0.88514_ep_2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG9nObyHFlBF"
      },
      "source": [
        "## Predicting on Test Data\n",
        "Using the best model we saved after fine-tuning the pre-trained BERT model, we now predict the classification of the tweets on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnvH0aHBjXNA",
        "outputId": "cdca7312-5522-4042-a020-03ef3dff252e"
      },
      "source": [
        "def test_prediction():\n",
        "\n",
        "    # path_to_model = MODELS + \"/bert-base-uncased_lr_3e-05_val_loss_0.5399_acc_0.88514_ep_2.pt\"\n",
        "\n",
        "    # load the best model for classification task\n",
        "    model = SentencePairClassifier(BERT_MODEL)\n",
        "    print(\"\\nLoading the weights of the model...\")\n",
        "    model.load_state_dict(torch.load(path_to_model, map_location=device))\n",
        "    model.to(device)\n",
        "\n",
        "    # use the trained model to predict class labels for the test set\n",
        "    print(\"Reading test data...\")\n",
        "    test_df = read_csv_datasets(PROJECT_DATA + 'test.csv')\n",
        "    test_set = TweetDataset(test_df, MAXLEN, False, BERT_MODEL)\n",
        "    test_loader = DataLoader(test_set, batch_size=BS, num_workers=2)\n",
        "    print(\"Done preprocessing test data.\")\n",
        "\n",
        "    print(\"Predicting on test data...\")\n",
        "    path_to_output_file = PROJECT_DATA + 'test-output-probabilities.txt'\n",
        "    predict_to_file(net=model, device=device, dataloader=test_loader, with_labels=False,\n",
        "                    result_file=path_to_output_file)\n",
        "    print(\"\\nTest classification probabilities are available in : {}\".format(path_to_output_file))\n",
        "\n",
        "    path_to_output_json = PROJECT_DATA + 'test-output.json'\n",
        "    save_result(test_df, path_to_output_file, path_to_output_json)\n",
        "\n",
        "test_prediction()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading the weights of the model...\n",
            "Reading test data...\n",
            "Done preprocessing test data.\n",
            "Predicting on test data...\n",
            "\n",
            "Test classification probabilities are available in : /content/drive/MyDrive/Colab Notebooks/NLP_Project/project-data/test-output-probabilities.txt\n",
            "Predictions are available in : /content/drive/MyDrive/Colab Notebooks/NLP_Project/project-data/test-output.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvD9TAUrT-0"
      },
      "source": [
        "# Rumour Analysis\n",
        "A simple sentiment analysis using TextBlob on and replies to main tweets classified as rumours and non-rumours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOflftUTvImy"
      },
      "source": [
        "## Predicting class labels of Covid data\n",
        "Before we can start doing some analysis on the Covid dataset, we first predict the classification of the tweets as either a rumour or non-rumour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hU4LMiRlgv_"
      },
      "source": [
        "def covid_prediction():\n",
        "\n",
        "    # path_to_model = MODELS + \"/bert-base-uncased_lr_3e-05_val_loss_0.5399_acc_0.88514_ep_2.pt\"\n",
        "\n",
        "    # load the best model for classification task\n",
        "    model = SentencePairClassifier(BERT_MODEL)\n",
        "    print(\"\\nLoading the weights of the model...\")\n",
        "    model.load_state_dict(torch.load(path_to_model, map_location=device))\n",
        "    model.to(device)\n",
        "\n",
        "    # use the trained model to predict class labels for the test set\n",
        "    print(\"Reading covid data...\")\n",
        "    covid_df = read_csv_datasets(PROJECT_DATA + 'covid.csv')\n",
        "    covid_set = TweetDataset(covid_df, MAXLEN, False, BERT_MODEL)\n",
        "    covid_loader = DataLoader(covid_set, batch_size=BS, num_workers=2)\n",
        "    print(\"Done preprocessing covid data.\")\n",
        "\n",
        "    print(\"Predicting on covid data...\")\n",
        "    path_to_output_file = PROJECT_DATA + 'covid-output-probabilities.txt'\n",
        "    predict_to_file(net=model, device=device, dataloader=covid_loader, with_labels=False,\n",
        "                    result_file=path_to_output_file)\n",
        "    print(\"\\nCovid classification probabilities are available in : {}\".format(path_to_output_file))\n",
        "\n",
        "    path_to_output_json = PROJECT_DATA + 'covid-output.json'\n",
        "    save_result(covid_df, path_to_output_file, path_to_output_json)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfQtcWFOvsE8"
      },
      "source": [
        "## Preparing the Covid dataset\n",
        "Next, we prepare the Covid dataset containing the replies to and the main tweets which will be our inputs for the Sentiment Analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UY_VNw9pTTK"
      },
      "source": [
        "def read_covid_data():\n",
        "    \"\"\"\n",
        "    Read covid datasets.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame()\n",
        "    with open(PROJECT_DATA + 'covid.data.jsonl', 'r', encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            line = json.loads(line)\n",
        "            tweet_id = line[0][\"id_str\"]\n",
        "            tweet = line[0][\"text\"]\n",
        "            datetime = line[0][\"created_at\"]\n",
        "            comments = \"\"\n",
        "            for row in line[1:]:\n",
        "                # use tweet preprocessor to clean text\n",
        "                comments += \" \" + row[\"text\"] + \".\"\n",
        "            data = data.append({\"id\":tweet_id,\"text\":tweet,\"datetime\":datetime,\"comments\":comments}, ignore_index=True)\n",
        "    f.close()\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def prepare_covid_data():\n",
        "    covid_data_ready = False\n",
        "    try:\n",
        "        covid_label = read_label(PROJECT_DATA + 'covid-output.json')\n",
        "        covid_data_ready = True\n",
        "    except:\n",
        "        print('Covid data not yet created.')\n",
        "        covid_prediction()\n",
        "\n",
        "    if not covid_data_ready:\n",
        "        covid_label = read_label(PROJECT_DATA + 'covid-output.json')\n",
        "\n",
        "    covid_data = read_covid_data()\n",
        "    covid_df = pd.merge(covid_data, covid_label, on=\"id\", how=\"outer\")\n",
        "\n",
        "    # Save covid data to csv for later use/re-use without having to re-execute everything\n",
        "    open(PROJECT_DATA + 'covid-data.csv','w', newline='').write(covid_df.to_csv(index=False))\n",
        "\n",
        "\n",
        "def get_covid_data():\n",
        "    try:\n",
        "        # check if covid data file exists\n",
        "        f = open(PROJECT_DATA + 'covid-data.csv', 'r')\n",
        "        f.close()\n",
        "    except:\n",
        "        prepare_covid_data()\n",
        "\n",
        "    covid_df = pd.read_csv(PROJECT_DATA + 'covid-data.csv', dtype={'id':str})\n",
        "    covid_df = covid_df.assign(datetime=pd.to_datetime(covid_df.datetime))\n",
        "\n",
        "    return covid_df"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-zTst8RyX00"
      },
      "source": [
        "## Sentiment Analysis using TextBlob\n",
        "We apply sentiment analysis on the main tweets and comments using TextBlob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4vOjNlZrJkj"
      },
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "def compute_sentiments():\n",
        "    sentiments = pd.DataFrame()\n",
        "    for row in range(len(covid_df)):\n",
        "        tweet_pol = TextBlob(covid_df['text'][row]).polarity\n",
        "        tweet_sub = TextBlob(covid_df['text'][row]).subjectivity\n",
        "\n",
        "        reply_pol = 0\n",
        "        reply_sub = 0\n",
        "        if isinstance(covid_df['comments'][row], str): # check that there is a comment or that comment value is not nan\n",
        "            reply_pol = TextBlob(covid_df['comments'][row]).polarity\n",
        "            reply_sub = TextBlob(covid_df['comments'][row]).subjectivity\n",
        "\n",
        "        sentiments = sentiments.append({\"id\":covid_df[\"id\"][row],\n",
        "                                        \"tweet sentiment\":tweet_pol,\n",
        "                                        \"tweet subjectivity\":tweet_sub,\n",
        "                                        \"reply sentiment\":reply_pol,\n",
        "                                        \"reply subjectivity\":reply_sub} , ignore_index=True)\n",
        "        \n",
        "    return sentiments\n",
        "\n",
        "    \n",
        "def save_sentiments():\n",
        "    covid_df = get_covid_data()\n",
        "    covid_df = covid_df.assign(datetime=pd.to_datetime(covid_df.datetime))\n",
        "\n",
        "    sentiments = compute_sentiments()\n",
        "    covid_sentiments = pd.merge(covid_df, sentiments, on=\"id\", how=\"outer\")\n",
        "    # Save covid data to csv for later use/re-use without having to re-execute everything\n",
        "    open(PROJECT_DATA + 'covid-sentiments.csv','w', newline='').write(covid_sentiments.to_csv(index=False))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "5SR5FpHuIIL2",
        "outputId": "7f1a37f5-9f5d-4640-aa76-45523d666dd6"
      },
      "source": [
        "try:\n",
        "    # check if covid data file exists\n",
        "    f = open(PROJECT_DATA + 'covid-sentiments.csv', 'r')\n",
        "    f.close()\n",
        "except:\n",
        "    save_sentiments()\n",
        "\n",
        "covid_sentiments = pd.read_csv(PROJECT_DATA + 'covid-sentiments.csv', dtype={'id':str})\n",
        "\n",
        "covid_sentiments"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>datetime</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>reply sentiment</th>\n",
              "      <th>reply subjectivity</th>\n",
              "      <th>tweet sentiment</th>\n",
              "      <th>tweet subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-06-14 20:20:28+00:00</td>\n",
              "      <td>1272262651100434433</td>\n",
              "      <td>According to the New York Times, Warner Bros. ...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.296591</td>\n",
              "      <td>0.644886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@TexasTribune Guess what the cause of death i...</td>\n",
              "      <td>2020-07-25 22:30:14+00:00</td>\n",
              "      <td>1287153210990395392</td>\n",
              "      <td>Hurricane Hanna has made landfall in Texas.\\n\\...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-05-30 02:22:04+00:00</td>\n",
              "      <td>1266555444283179008</td>\n",
              "      <td>Monkeys on the loose in India with stolen coro...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.269231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@BelAkinyii Let's not play blind that the wor...</td>\n",
              "      <td>2020-05-05 16:54:05+00:00</td>\n",
              "      <td>1257715199655755779</td>\n",
              "      <td>Eastleigh and Swahili Arabs in Mombasa where c...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.091667</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@HeidiNBC #coronavirus is very happy. @HeidiN...</td>\n",
              "      <td>2020-06-20 13:50:23+00:00</td>\n",
              "      <td>1274338812173393920</td>\n",
              "      <td>“If Trump felt comfortable having it here, the...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.038419</td>\n",
              "      <td>0.637582</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17453</th>\n",
              "      <td>@funder USA (Real Sick-Man of the World)'s CO...</td>\n",
              "      <td>2020-04-13 01:01:10+00:00</td>\n",
              "      <td>1249502859185590272</td>\n",
              "      <td>I wonder how many lives could’ve been saved if...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.059687</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17454</th>\n",
              "      <td>@NadineDorries @thetimes More Tory Lies ...\\n...</td>\n",
              "      <td>2020-07-17 09:00:50+00:00</td>\n",
              "      <td>1284050414619459586</td>\n",
              "      <td>The @thetimes front page on 17th March. The fi...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>-0.017972</td>\n",
              "      <td>0.435589</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17455</th>\n",
              "      <td>@DNCWarRoom Fact check: Chinese is not a race...</td>\n",
              "      <td>2020-06-21 00:51:54+00:00</td>\n",
              "      <td>1274505289614725122</td>\n",
              "      <td>Trump just completed the racism trifecta in a ...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.388889</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17456</th>\n",
              "      <td>@Jess__Taylor__ @davidallengreen Eck! What ar...</td>\n",
              "      <td>2020-06-02 18:23:49+00:00</td>\n",
              "      <td>1267884642637676545</td>\n",
              "      <td>Here are a few of my photographs from today’s ...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>-0.041667</td>\n",
              "      <td>0.461111</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17457</th>\n",
              "      <td>@seanhannity DeBlasio caused NYC's lockdown c...</td>\n",
              "      <td>2020-05-28 00:27:01+00:00</td>\n",
              "      <td>1265801718958301184</td>\n",
              "      <td>‘IT’S GONE’: Bill De Blasio Says NYC Facing $9...</td>\n",
              "      <td>non-rumour</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>0.387035</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17458 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                comments  ... tweet subjectivity\n",
              "0                                                    NaN  ...           0.644886\n",
              "1       @TexasTribune Guess what the cause of death i...  ...           0.000000\n",
              "2                                                    NaN  ...           0.269231\n",
              "3       @BelAkinyii Let's not play blind that the wor...  ...           0.100000\n",
              "4       @HeidiNBC #coronavirus is very happy. @HeidiN...  ...           0.800000\n",
              "...                                                  ...  ...                ...\n",
              "17453   @funder USA (Real Sick-Man of the World)'s CO...  ...           0.300000\n",
              "17454   @NadineDorries @thetimes More Tory Lies ...\\n...  ...           0.200000\n",
              "17455   @DNCWarRoom Fact check: Chinese is not a race...  ...           0.833333\n",
              "17456   @Jess__Taylor__ @davidallengreen Eck! What ar...  ...           0.100000\n",
              "17457   @seanhannity DeBlasio caused NYC's lockdown c...  ...           0.375000\n",
              "\n",
              "[17458 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}